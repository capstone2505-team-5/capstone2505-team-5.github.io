<!DOCTYPE html><html lang="en" data-astro-cid-37fxchfa> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/images/Updated OG Symbol White.svg"><title>LLMonade</title><link rel="stylesheet" href="/_astro/case-study.Bb7KtGgU.css">
<link rel="stylesheet" href="/_astro/case-study.B4DvFMUD.css"></head> <body data-astro-cid-37fxchfa>  <header class="header" data-astro-cid-ymhdp2rl> <nav class="nav" data-astro-cid-ymhdp2rl> <div class="nav-brand" data-astro-cid-ymhdp2rl> <a href="/" class="nav-brand-link" data-astro-cid-ymhdp2rl> <img src="/images/Updated OG Symbol.png" alt="LLMonade" class="nav-symbol" data-astro-cid-ymhdp2rl> <img src="/images/Updated OG Tag Dark.png" alt="" class="nav-tag" data-astro-cid-ymhdp2rl> </a> </div> <div class="nav-links" data-astro-cid-ymhdp2rl> <a href="/case-study" class="nav-link active" data-astro-cid-ymhdp2rl>Case Study</a> <a href="/#team" class="nav-link" data-astro-cid-ymhdp2rl>Team</a> <a href="https://github.com/capstone2505-team-5" target="_blank" rel="noopener noreferrer" class="nav-link github-link" data-astro-cid-ymhdp2rl>
GitHub
<svg class="github-icon" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" data-astro-cid-ymhdp2rl> <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z" data-astro-cid-ymhdp2rl></path> </svg> </a> </div> </nav> </header>  <div class="case-study-layout" data-astro-cid-nnb3tz64> <aside class="sidebar" data-astro-cid-nnb3tz64> <nav class="sidebar-nav" data-astro-cid-nnb3tz64> <ul class="sidebar-nav-list" data-astro-cid-nnb3tz64> <li data-astro-cid-nnb3tz64> <a href="#introduction" class="sidebar-nav-item" data-section="introduction" data-astro-cid-nnb3tz64>Introduction</a> <ul class="sidebar-nav-sub-list" data-astro-cid-nnb3tz64> <li data-astro-cid-nnb3tz64><a href="#what-is-llmonade" class="sidebar-nav-sub-item" data-section="what-is-llmonade" data-astro-cid-nnb3tz64>What is LLMonade?</a></li> </ul> </li><li data-astro-cid-nnb3tz64> <a href="#background" class="sidebar-nav-item" data-section="background" data-astro-cid-nnb3tz64>Background</a> <ul class="sidebar-nav-sub-list" data-astro-cid-nnb3tz64> <li data-astro-cid-nnb3tz64><a href="#observability-of-traditional-apps" class="sidebar-nav-sub-item" data-section="observability-of-traditional-apps" data-astro-cid-nnb3tz64>Observability of Traditional Apps</a></li><li data-astro-cid-nnb3tz64><a href="#ai-llms-and-llm-based-apps" class="sidebar-nav-sub-item" data-section="ai-llms-and-llm-based-apps" data-astro-cid-nnb3tz64>AI, LLMs, and LLM-based Apps</a></li><li data-astro-cid-nnb3tz64><a href="#observability-of-llm-based-apps" class="sidebar-nav-sub-item" data-section="observability-of-llm-based-apps" data-astro-cid-nnb3tz64>Observability of LLM-based Apps</a></li> </ul> </li><li data-astro-cid-nnb3tz64> <a href="#our-solution" class="sidebar-nav-item" data-section="our-solution" data-astro-cid-nnb3tz64>Our Solution</a> <ul class="sidebar-nav-sub-list" data-astro-cid-nnb3tz64> <li data-astro-cid-nnb3tz64><a href="#the-solution" class="sidebar-nav-sub-item" data-section="the-solution" data-astro-cid-nnb3tz64>The Solution</a></li> </ul> </li><li data-astro-cid-nnb3tz64> <a href="#architecture" class="sidebar-nav-item" data-section="architecture" data-astro-cid-nnb3tz64>Architecture</a> <ul class="sidebar-nav-sub-list" data-astro-cid-nnb3tz64> <li data-astro-cid-nnb3tz64><a href="#the-architecture" class="sidebar-nav-sub-item" data-section="the-architecture" data-astro-cid-nnb3tz64>The Architecture</a></li> </ul> </li><li data-astro-cid-nnb3tz64> <a href="#engineering-challenges" class="sidebar-nav-item" data-section="engineering-challenges" data-astro-cid-nnb3tz64>Engineering Challenges</a> <ul class="sidebar-nav-sub-list" data-astro-cid-nnb3tz64> <li data-astro-cid-nnb3tz64><a href="#collecting-traces" class="sidebar-nav-sub-item" data-section="collecting-traces" data-astro-cid-nnb3tz64>Collecting Traces</a></li><li data-astro-cid-nnb3tz64><a href="#data-ingestion" class="sidebar-nav-sub-item" data-section="data-ingestion" data-astro-cid-nnb3tz64>Data Ingestion</a></li><li data-astro-cid-nnb3tz64><a href="#standardizing-our-platform" class="sidebar-nav-sub-item" data-section="standardizing-our-platform" data-astro-cid-nnb3tz64>Standardizing our Platform</a></li><li data-astro-cid-nnb3tz64><a href="#serverless-architecture" class="sidebar-nav-sub-item" data-section="serverless-architecture" data-astro-cid-nnb3tz64>Serverless Architecture</a></li> </ul> </li><li data-astro-cid-nnb3tz64> <a href="#future-work" class="sidebar-nav-item" data-section="future-work" data-astro-cid-nnb3tz64>Future Work</a> <ul class="sidebar-nav-sub-list" data-astro-cid-nnb3tz64> <li data-astro-cid-nnb3tz64><a href="#integrate-with-more-ai-observability-platforms" class="sidebar-nav-sub-item" data-section="integrate-with-more-ai-observability-platforms" data-astro-cid-nnb3tz64>Integrate with More AI Observability Platforms</a></li><li data-astro-cid-nnb3tz64><a href="#expand-deployment-options" class="sidebar-nav-sub-item" data-section="expand-deployment-options" data-astro-cid-nnb3tz64>Expand Deployment Options</a></li><li data-astro-cid-nnb3tz64><a href="#provide-more-app-functionality" class="sidebar-nav-sub-item" data-section="provide-more-app-functionality" data-astro-cid-nnb3tz64>Provide More App Functionality</a></li> </ul> </li> </ul> </nav> </aside> <main class="main-content" data-astro-cid-nnb3tz64> <section id="introduction" class="content-section" data-astro-cid-nnb3tz64> <h2 data-astro-cid-nnb3tz64>Introduction</h2> <div class="case-study-content"> <h3 id="what-is-llmonade">What is LLMonade?</h3> <p>LLMonade is an open-source AI evaluation tool that helps small development teams systematically improve their LLM-integrated applications through guided, manual error analysis. Instead of guessing what's wrong with your AI application, our streamlined interface pulls your real trace data, lets you quickly annotate outputs, automatically categorize failure patterns, and identify the highest ROI fixes. We make the proven best practice of manual error analysis accessible to teams with limited resources and new to AI evaluations.</p> </div>      </section><section id="background" class="content-section" data-astro-cid-nnb3tz64> <h2 data-astro-cid-nnb3tz64>Background</h2>  <div class="case-study-content"> <h3 id="observability-of-traditional-apps">Observability of Traditional Apps</h3> <p>
Traditional applications follow well-established patterns for observability. 
    These applications typically have predictable request flows, clear error boundaries, 
    and structured data that makes monitoring and debugging straightforward.
</p> <div class="highlight-box"> <h4>Key Highlights</h4> <ul> <li>Comprehensive user research with 50+ participants</li> <li>Iterative design process with 3 major iterations</li> <li>40% improvement in user satisfaction scores</li> <li>25% reduction in task completion time</li> </ul> </div> <div class="content-block"> <h4>Key Characteristics</h4> <ul> <li>Predictable request/response patterns</li> <li>Structured error handling</li> <li>Clear data flow boundaries</li> <li>Established monitoring patterns</li> </ul> </div> <h3 id="ai-llms-and-llm-based-apps">AI, LLMs, and LLM-based Apps</h3> <p>
The emergence of Large Language Models (LLMs) and AI-powered applications 
    has introduced new challenges for observability. These applications often 
    have non-deterministic outputs, complex reasoning chains, and unique 
    performance characteristics.
</p> <div class="content-block"> <h4>New Challenges</h4> <ul> <li>Non-deterministic outputs</li> <li>Complex reasoning chains</li> <li>Variable response times</li> <li>Context-dependent behavior</li> </ul> </div> <h3 id="observability-of-llm-based-apps">Observability of LLM-based Apps</h3> <p>
Observing LLM-based applications requires new approaches and tools. 
    Traditional metrics like response time and error rates are still important, 
    but we need additional insights into the quality, relevance, and reasoning 
    behind AI-generated responses.
</p> <div class="content-block"> <h4>Observability Requirements</h4> <ul> <li>Response quality assessment</li> <li>Reasoning chain analysis</li> <li>Token usage monitoring</li> <li>Context tracking</li> </ul> </div> </div>     </section><section id="our-solution" class="content-section" data-astro-cid-nnb3tz64> <h2 data-astro-cid-nnb3tz64>Our Solution</h2>    <div class="case-study-content"> <h3 id="the-solution">The Solution</h3> <p>
The implementation of our observability platform involved careful consideration 
    of various technical challenges and requirements. We chose technologies that 
    would provide the best balance of performance, scalability, and ease of use.
</p> <div class="carousel-container" data-astro-cid-wfe7xcno> <h3 class="carousel-title" data-astro-cid-wfe7xcno>The Team</h3> <div class="carousel-wrapper" data-astro-cid-wfe7xcno> <button class="carousel-arrow carousel-arrow-left" aria-label="Previous image" data-astro-cid-wfe7xcno> <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" data-astro-cid-wfe7xcno> <path d="M15.41 7.41L14 6l-6 6 6 6 1.41-1.41L10.83 12z" data-astro-cid-wfe7xcno></path> </svg> </button> <div class="carousel-track" data-astro-cid-wfe7xcno> <div class="carousel-slide" data-index="0" data-astro-cid-wfe7xcno> <img src="/images/team/Justin.jpg" alt="Justin" class="carousel-image" data-astro-cid-wfe7xcno> <div class="carousel-caption" data-astro-cid-wfe7xcno> <p data-astro-cid-wfe7xcno>This is and example of a caption for the photo of Justin</p> </div> </div><div class="carousel-slide" data-index="1" data-astro-cid-wfe7xcno> <img src="/images/team/Josh.png" alt="Josh" class="carousel-image" data-astro-cid-wfe7xcno> <div class="carousel-caption" data-astro-cid-wfe7xcno> <p data-astro-cid-wfe7xcno>This is and example of a caption for the photo of Josh</p> </div> </div><div class="carousel-slide" data-index="2" data-astro-cid-wfe7xcno> <img src="/images/team/Noah.jpg" alt="Noah" class="carousel-image" data-astro-cid-wfe7xcno> <div class="carousel-caption" data-astro-cid-wfe7xcno> <p data-astro-cid-wfe7xcno>This is and example of a caption for the photo of Noah</p> </div> </div><div class="carousel-slide" data-index="3" data-astro-cid-wfe7xcno> <img src="/images/team/Alex.jpeg" alt="Alex" class="carousel-image" data-astro-cid-wfe7xcno> <div class="carousel-caption" data-astro-cid-wfe7xcno> <p data-astro-cid-wfe7xcno>This is and example of a caption for the photo of Alex. This is a long caption that should wrap around to the next line. It should keep wrapping around until the end of the next line and the next line and the next line and the next line.</p> </div> </div> </div> <button class="carousel-arrow carousel-arrow-right" aria-label="Next image" data-astro-cid-wfe7xcno> <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" data-astro-cid-wfe7xcno> <path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z" data-astro-cid-wfe7xcno></path> </svg> </button> </div> <div class="carousel-indicators" data-astro-cid-wfe7xcno> <button class="carousel-indicator" data-index="0" aria-label="Go to image 1" data-astro-cid-wfe7xcno> <span class="indicator-dot" data-astro-cid-wfe7xcno></span> </button><button class="carousel-indicator" data-index="1" aria-label="Go to image 2" data-astro-cid-wfe7xcno> <span class="indicator-dot" data-astro-cid-wfe7xcno></span> </button><button class="carousel-indicator" data-index="2" aria-label="Go to image 3" data-astro-cid-wfe7xcno> <span class="indicator-dot" data-astro-cid-wfe7xcno></span> </button><button class="carousel-indicator" data-index="3" aria-label="Go to image 4" data-astro-cid-wfe7xcno> <span class="indicator-dot" data-astro-cid-wfe7xcno></span> </button> </div> </div> <script type="module">class n{container;track;slides;indicators;leftArrow;rightArrow;currentIndex;totalSlides;constructor(t){this.container=t,this.track=t.querySelector(".carousel-track"),this.slides=Array.from(t.querySelectorAll(".carousel-slide")),this.indicators=Array.from(t.querySelectorAll(".carousel-indicator")),this.leftArrow=t.querySelector(".carousel-arrow-left"),this.rightArrow=t.querySelector(".carousel-arrow-right"),this.currentIndex=0,this.totalSlides=this.slides.length,this.init()}init(){this.updateSlides(),this.updateIndicators(),this.bindEvents()}bindEvents(){this.leftArrow?.addEventListener("click",()=>this.previous()),this.rightArrow?.addEventListener("click",()=>this.next()),this.indicators.forEach((e,s)=>{e.addEventListener("click",()=>this.goTo(s))}),this.container.addEventListener("keydown",e=>{e.key==="ArrowLeft"?(e.preventDefault(),this.previous()):e.key==="ArrowRight"&&(e.preventDefault(),this.next())});let t=0,r=0;this.container.addEventListener("touchstart",e=>{t=e.touches[0].clientX}),this.container.addEventListener("touchend",e=>{r=e.changedTouches[0].clientX,this.handleSwipe(t,r)})}handleSwipe(t,r){const s=t-r;Math.abs(s)>50&&(s>0?this.next():this.previous())}previous(){this.currentIndex=this.currentIndex===0?this.totalSlides-1:this.currentIndex-1,this.updateSlides(),this.updateIndicators()}next(){this.currentIndex=this.currentIndex===this.totalSlides-1?0:this.currentIndex+1,this.updateSlides(),this.updateIndicators()}goTo(t){this.currentIndex=t,this.updateSlides(),this.updateIndicators()}updateSlides(){this.slides.forEach((t,r)=>{if(t.style.transform=`translateX(${(r-this.currentIndex)*100}%)`,t.setAttribute("aria-hidden",r!==this.currentIndex?"true":"false"),r===this.currentIndex){const e=t.scrollHeight;this.track.style.height=`${e}px`}})}updateIndicators(){this.indicators.forEach((t,r)=>{r===this.currentIndex?(t.classList.add("active"),t.setAttribute("aria-current","true")):(t.classList.remove("active"),t.removeAttribute("aria-current"))})}}document.addEventListener("DOMContentLoaded",()=>{document.querySelectorAll(".carousel-container").forEach(t=>new n(t))});</script>  <div class="tech-stack"> <div class="tech-category"> <h4>Frontend Technologies</h4> <ul> <li>React.js for interactive dashboards</li> <li>TypeScript for type safety</li> <li>D3.js for data visualization</li> <li>Tailwind CSS for styling</li> </ul> </div> <div class="tech-category"> <h4>Backend Services</h4> <ul> <li>AWS Lambda for serverless functions</li> <li>Amazon DynamoDB for data storage</li> <li>AWS API Gateway for REST APIs</li> <li>Amazon CloudWatch for monitoring</li> </ul> </div> <div class="tech-category"> <h4>Data Processing</h4> <ul> <li>Apache Kafka for event streaming</li> <li>Apache Flink for real-time processing</li> <li>Elasticsearch for search and analytics</li> <li>Redis for caching</li> </ul> </div> </div> <h3>Development Process</h3> <p>
Our development process followed an iterative approach with regular feedback 
    loops and continuous integration. This ensured that we could quickly adapt 
    to changing requirements and user feedback.
</p> <div class="process-timeline"> <div class="timeline-item"> <div class="timeline-marker">1</div> <div class="timeline-content"> <h4>Research & Planning</h4> <p>Comprehensive analysis of existing observability solutions and identification of gaps for LLM applications.</p> </div> </div> <div class="timeline-item"> <div class="timeline-marker">2</div> <div class="timeline-content"> <h4>Prototype Development</h4> <p>Rapid prototyping of core functionality to validate technical approaches and gather early feedback.</p> </div> </div> <div class="timeline-item"> <div class="timeline-marker">3</div> <div class="timeline-content"> <h4>Core Implementation</h4> <p>Development of the main platform components with focus on scalability and performance.</p> </div> </div> <div class="timeline-item"> <div class="timeline-marker">4</div> <div class="timeline-content"> <h4>Testing & Optimization</h4> <p>Comprehensive testing across different scenarios and performance optimization based on real-world usage.</p> </div> </div> </div> </div>   </section><section id="architecture" class="content-section" data-astro-cid-nnb3tz64> <h2 data-astro-cid-nnb3tz64>Architecture</h2>   <div class="case-study-content"> <h3 id="the-architecture">The Architecture</h3> <p>
Our observability platform has delivered significant improvements across 
    multiple key performance indicators. The results demonstrate the effectiveness of our approach to monitoring LLM-based applications.
</p> <div class="metrics-grid"> <div class="metric-card"> <div class="metric-value">85%</div> <div class="metric-label">Faster Issue Detection</div> <div class="metric-description">Reduced time to identify and diagnose problems in LLM applications</div> </div> <div class="metric-card"> <div class="metric-value">60%</div> <div class="metric-label">Reduced Debugging Time</div> <div class="metric-description">Faster resolution of issues through better observability</div> </div> <div class="metric-card"> <div class="metric-value">40%</div> <div class="metric-label">Cost Optimization</div> <div class="metric-description">Better resource utilization through improved monitoring</div> </div> <div class="metric-card"> <div class="metric-value">95%</div> <div class="metric-label">Uptime Improvement</div> <div class="metric-description">Enhanced reliability through proactive monitoring</div> </div> </div> <h3>User Experience Impact</h3> <p>
The implementation of our observability platform has had a profound impact 
    on the user experience for both developers and end users of LLM applications.
</p> <div class="impact-section"> <div class="impact-card"> <h4>Developer Experience</h4> <ul> <li>Faster debugging and troubleshooting</li> <li>Better understanding of application behavior</li> <li>Improved confidence in deployments</li> <li>Reduced time spent on support issues</li> </ul> </div> <div class="impact-card"> <h4>End User Experience</h4> <ul> <li>More reliable and consistent responses</li> <li>Faster response times</li> <li>Better error handling and recovery</li> <li>Improved overall satisfaction</li> </ul> </div> </div> <h3>Business Impact</h3> <p>
Beyond technical metrics, our observability platform has delivered 
    measurable business value through improved operational efficiency 
    and reduced costs.
</p> <div class="business-metrics"> <div class="business-metric"> <h4>Operational Efficiency</h4> <p>Reduced mean time to resolution (MTTR) by 70% through better visibility into system performance and faster issue identification.</p> </div> <div class="business-metric"> <h4>Cost Savings</h4> <p>Achieved 30% reduction in infrastructure costs through better resource utilization and proactive scaling.</p> </div> <div class="business-metric"> <h4>Scalability</h4> <p>Successfully handled 10x increase in traffic without proportional increase in operational overhead.</p> </div> </div> </div>    </section><section id="engineering-challenges" class="content-section" data-astro-cid-nnb3tz64> <h2 data-astro-cid-nnb3tz64>Engineering Challenges</h2>     <div class="case-study-content"> <h3 id="collecting-traces">Collecting Traces</h3> <p>
Our approach to collecting traces from LLM-based applications involves 
    instrumenting key points in the request flow to capture both traditional 
    metrics and LLM-specific data points.
</p> <div class="content-block"> <h4>Trace Collection Strategy</h4> <ul> <li>Request/response instrumentation</li> <li>LLM API call tracking</li> <li>Token usage monitoring</li> <li>Context and prompt capture</li> </ul> </div> <h3 id="data-ingestion">Data Ingestion</h3> <p>
The data ingestion pipeline processes and transforms raw trace data 
    into a format suitable for analysis and visualization. This includes 
    normalization, enrichment, and storage optimization.
</p> <div class="content-block"> <h4>Ingestion Pipeline</h4> <ul> <li>Real-time data processing</li> <li>Schema validation and normalization</li> <li>Data enrichment with metadata</li> <li>Efficient storage optimization</li> </ul> </div> <h3 id="standardizing-our-platform">Standardizing our Platform</h3> <p>
To ensure consistency across different LLM applications, we developed 
    a standardized platform that provides common interfaces, data formats, 
    and monitoring capabilities.
</p> <div class="content-block"> <h4>Platform Standards</h4> <ul> <li>Unified data schema</li> <li>Common API interfaces</li> <li>Standardized metrics</li> <li>Consistent visualization</li> </ul> </div> <h3 id="serverless-architecture">Serverless Architecture</h3> <p>
Our observability platform leverages serverless architecture to provide 
    scalable, cost-effective monitoring without the overhead of managing 
    infrastructure.
</p> <div class="content-block"> <h4>Serverless Benefits</h4> <ul> <li>Automatic scaling</li> <li>Pay-per-use pricing</li> <li>Reduced operational overhead</li> <li>Built-in high availability</li> </ul> </div> </div>  </section><section id="future-work" class="content-section" data-astro-cid-nnb3tz64> <h2 data-astro-cid-nnb3tz64>Future Work</h2>      <div class="case-study-content"> <h3 id="integrate-with-more-ai-observability-platforms">Integrate with More AI Observability Platforms</h3> <p>Currently, we only offer our evaluation to those who are using Phoenix as their observability platform. There are many other observability platforms such as Braintrust, Langfuse, and Langsmith that we could integrate with so that users aren’t locked in to Phoenix. Furthermore, in addition to automated trace collection, we would like to offer users the option to directly upload trace data through CSV or JSON files to have more direct management over what traces they want to evaluate.</p> <h3 id="expand-deployment-options">Expand Deployment Options</h3> <p>Because AI applications are so new, there are many developers who haven’t set up an observability tool yet. We could provide an option in our CLI to deploy Phoenix tracing infrastructure within the same AWS architecture as LLMonade - an all in one package to get setup with LLM observability and evaluation.</p> <p>Since LLM data, especially user inputs, can contain sensitive information, we would also like to offer deployment mechanisms that support different security constraints such as access through VPN.</p> <p>Finally, not every team uses AWS, so in the future we would like to transition from using AWS CDK and instead use Terraform to allow users to deploy to other cloud providers such as Microsoft Azure and Google Cloud Platform (GCP).</p> <h3 id="provide-more-app-functionality">Provide More App Functionality</h3> <p>Future development will focus on more comprehensive evaluation processes. We could enable viewing of entire traces across multiple spans, beyond our current root span focus, to give users a deeper insight into their LLM applications. </p> <p>Context enhancement also represents a major area for future improvement. Future iterations can incorporate richer metadata on traces, API calls to external services, and introduce moveable and resizeable interface components for a more customizable user experience.</p> <p>Finally, using synthetic datasets alongside real traces could enable experimental testing scenarios for applications still in development, allowing teams to evaluate their LLM systems before they have real user data. </p> <p>As companies scale and generate larger volumes of traces, manual evaluation becomes unfeasible so we could add LLM-as-a-judge functionality. This would enable automated evaluation scoring allowing our application to support teams as their evaluation workloads grow. These enhancements would allow users to start out with a simplified error analysis workflow and gradually transition to an automated evaluation platform with guidance at every step.</p> </div> </section> </main> </div>  </body></html> <script type="module">const l={rootMargin:"-20% 0px -70% 0px",threshold:0},d=new IntersectionObserver(c=>{c.forEach(s=>{const r=s.target.getAttribute("id"),i=document.querySelector(`[data-section="${r}"]`),t=document.querySelector(`[data-section="${r}"]`);if(s.isIntersecting)if(document.querySelectorAll(".sidebar-nav-item, .sidebar-nav-sub-item").forEach(e=>{e.classList.remove("active")}),s.target.tagName==="H3"){const e=s.target.closest(".content-section");if(e){const n=e.getAttribute("id"),o=document.querySelector(`[data-section="${n}"]`);o&&o.classList.add("active")}t&&t.classList.add("active")}else i&&i.classList.add("active")})},l);document.addEventListener("DOMContentLoaded",()=>{const c=document.querySelectorAll(".content-section"),s=document.querySelectorAll("h3[id]");c.forEach(t=>{d.observe(t)}),s.forEach(t=>{d.observe(t)}),document.querySelectorAll(".sidebar-nav-item").forEach(t=>{t.addEventListener("click",e=>{e.preventDefault();const n=t.getAttribute("href")?.substring(1),o=document.getElementById(n||"");if(o){const a=o.offsetTop-80;window.scrollTo({top:a,behavior:"smooth"})}})}),document.querySelectorAll(".sidebar-nav-sub-item").forEach(t=>{t.addEventListener("click",e=>{e.preventDefault();const n=t.getAttribute("href")?.substring(1),o=document.getElementById(n||"");if(o){const a=o.offsetTop-80;window.scrollTo({top:a,behavior:"smooth"})}})})});</script> 