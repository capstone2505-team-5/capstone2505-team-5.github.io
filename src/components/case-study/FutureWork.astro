---
// Implementation.astro - Case Study Implementation Section
import Image from "../Image.astro";
---

<div class="case-study-content">
  <h3 id="integrate-with-more-ai-observability-platforms">Integrate with Additional AI Observability Platforms</h3>
  <p>Currently, we only offer our evaluation tool to development teams that have instrumented their application with the Phoenix observability platform. There are many other observability platforms such as Braintrust, Langfuse, and Langsmith that we could integrate with so that users are not locked into Phoenix. In addition to automated trace collection, we would like to offer users the option to directly upload trace data through CSV or JSON files. This would allow any development team, regardless of their observability setup, to use LLMonade.</p>

  <Image 
  src="/images/Future/_future-platforms-final-edit2.png" 
  alt="Cloud providers" 
  caption="" 
  clickable={true}
  width="500px"
  height="350px"
/>

  <h3 id="expand-deployment-options">Expand Deployment Options</h3>
  <p>Because AI applications are so new, there are many development teams that haven't set up an observability tool yet. In the future, we want to provide an option in our CLI to deploy Phoenix tracing infrastructure within the same AWS architecture as LLMonade. LLMonade would become an all-in-one setup of LLM observability and evaluation.</p>

  <p>A key priority on our future roadmap is to enhance our deployment capabilities for security-conscious organizations. We recognize that LLM trace data can contain sensitive information, so we plan to introduce options for stricter network controls. This will likely include the ability to require user access through a VPN.</p>

  <p>Finally, we recognize that our current deployment process is limited to AWS, which excludes teams using other cloud providers. To address this, a future goal is to transition our infrastructure-as-code from AWS CDK to Terraform, enabling support for platforms like Microsoft Azure and Google Cloud Platform (GCP).</p>

  <Image 
    src="/images/Future/cloud-providers-light-gradient.png" 
    alt="Cloud providers" 
    caption="" 
    clickable={true}
    width="600px"
    height="400px"
  />

  <h3 id="additional-metadata">Additional Metadata</h3>
  <p>Looking ahead, we plan to enhance the capabilities of our annotation viewer. We want to expand beyond the root span to display the full trace, including all nested spans, tool calls, and associated metadata. This would allow the reviewer to find errors anywhere in the chain and also provide more context for analysis.</p>

  <p>Currently, the annotation screen offers an extra context window for analyzers to drag and drop a PDF or image. We want to add the capability to upload more file types, input a URL, or make an API call here. Additionally, we would like to make the input, output, and context windows resizable and movable.</p>

  <h3 id="synthetic-data">Synthetic Data</h3>
  <p>In the future, we would like to support pre-production evaluation. We plan to introduce a feature that helps users generate synthetic datasets tailored to their application's use cases. This will allow teams to run their LLM application against these inputs and seamlessly ingest the resulting traces for immediate error analysisâ€“enabling them to find and fix bugs before launch.</p>

  <h3 id="automated-evaluations-with-llm-as-a-judge">Automated Evaluations with LLM-as-a-Judge</h3>
  <p>Our long-term vision is to help users graduate from manual error analysis to continuous, automated evaluations. We plan to build features that allow teams to use their curated error analysis results as a foundation for an automated regression suite. By leveraging an "LLM-as-a-Judge" model, this system will ensure that output quality remains high as changes are made to their application. This feature would allow users to start out with a simplified error analysis workflow and gradually transition to an automated evaluation system with guidance at every step.</p>

</div>


