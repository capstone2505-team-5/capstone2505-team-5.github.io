---
// Architecture.astro - Case Study Architecture Section
import Image from '../Image.astro';
---

<div class="case-study-content">
  <p>The architecture of LLMonade can be best understood by following the lifecycle of a root span as it moves through the ingestion stage and evaluation workflow. This will highlight how each component fits together and how the serverless architecture minimizes operational overhead and ensures scalability.</p>
  <ol>
    <li>Trace Generation with Phoenix</li>
    <li>Root Spans ETL Pipeline</li>
    <li>Evaluation Data Persistence</li>
    <li>Error Analysis Fullstack Application</li>
  </ol>

  <Image 
  src="/images/LLMonade-Architecture-Overview.png" 
  alt="System Architecture" 
  caption="High Level System Architecture"
  width="600px"
  height="400px"
  bordered={true}
  rounded={true}
  clickable={true}
/>

  <h3 id="trace-generation">Trace Generation with Phoenix</h3>
  <p>Traces are generated in a user’s LLM-powered application and are structured, organized, and stored by the observability platform Phoenix.  LLMonade builds upon this existing architecture to retrieve the highest level spans, the root spans, from the Phoenix database.</p>

  <h3 id="root-spans-etl-pipeline">Root Spans ETL Pipeline</h3>
  <p>The Root Spans ETL Pipeline is a serverless workflow, powered by AWS Lambda, that ingests data from Phoenix and loads it into LLMonade’s database. When LLMonade is deployed, the data pipeline immediately performs API requests to Phoenix and starts ingesting the pre-existing root spans.</p>

  <h3 id="evaluation-data-persistence">Evaluation Data Persistence</h3>

  <p>All ingested root spans and associated evaluation data are persisted in a PostgreSQL database hosted on AWS Relational Database Service (RDS). The database stores both the raw trace data from Phoenix and associated data generated during LLMonade’s evaluation workflow.  This includes formatted span data, batch groupings, grading notes, and custom error categories. A relational model is well-suited for this use case due to the structured nature of spans and associated evaluation data.</p>

  <h3 id="error-analysis-fullstack-application">Error Analysis Fullstack Application</h3>

  <p>When users access LLMonade, they connect through a CloudFront endpoint. On first access, requests are redirected through Lambda@Edge and Cognito, which enforce authentication and issue valid tokens. Once authenticated, users are served the React frontend from Amazon S3 via CloudFront, ensuring fast and secure delivery. From there, authenticated requests from the frontend are routed via the API Gateway to the backend API hosted on AWS Lambda. </p>
  <p>In addition to the API Lambda, we implemented a dedicated, asynchronous worker Lambda.  This Lambda function handles the time-intensive task of formatting spans. When a formatting job is initiated, our primary application API invokes multiple instances of this worker function. This offloads the heavy processing, ensuring the main API remains responsive and available for user requests.</p>
  <p>LLMonade leverages a serverless architecture, which is highly cost-effective for periodic workloads like error analysis. The pay-per-use model of AWS Lambda eliminates idle infrastructure costs, while its scalability seamlessly handles concurrent user activity.</p>

</div>


